{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\youss\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense , Flatten  , Conv2D , MaxPooling2D , Dropout,BatchNormalization, ReLU, Add, GlobalAveragePooling2D,Input\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import tf2onnx\n",
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the main directory containing subdirectories of labeled images\n",
    "main_directory = 'Data'\n",
    "\n",
    "# Initialize lists to store image data and labels\n",
    "image_data_list = []\n",
    "labels = []\n",
    "\n",
    "# Function to load and preprocess an image using OpenCV\n",
    "def load_image(image_path, target_size=(64, 64)):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, target_size)\n",
    "    return image\n",
    "\n",
    "# Walk through the directory structure\n",
    "for root, dirs, files in os.walk(main_directory):\n",
    "    \n",
    "    for file in files:\n",
    "        if file.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
    "            image_path = os.path.join(root, file)\n",
    "            label = os.path.basename(root)\n",
    "            image_data = load_image(image_path)\n",
    "\n",
    "            image_data_list.append(image_data)\n",
    "            labels.append(label)\n",
    "\n",
    "\n",
    "image_data_list= np.array(image_data_list)\n",
    "labels=np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = image_data_list / 255.0\n",
    "label_to_index = {label: idx for idx, label in enumerate(np.unique(labels))}\n",
    "indexed_labels = np.array([label_to_index[label] for label in labels])\n",
    "\n",
    "# One-hot encode the labels\n",
    "num_classes = len(np.unique(indexed_labels))\n",
    "y = to_categorical(indexed_labels, num_classes)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "49/49 [==============================] - 13s 233ms/step - loss: 2.0986 - accuracy: 0.3372 - val_loss: 1.1800 - val_accuracy: 0.5556\n",
      "Epoch 2/20\n",
      "49/49 [==============================] - 11s 223ms/step - loss: 1.1755 - accuracy: 0.5767 - val_loss: 0.7677 - val_accuracy: 0.6873\n",
      "Epoch 3/20\n",
      "49/49 [==============================] - 10s 207ms/step - loss: 0.8153 - accuracy: 0.6926 - val_loss: 0.5614 - val_accuracy: 0.7881\n",
      "Epoch 4/20\n",
      "49/49 [==============================] - 10s 208ms/step - loss: 0.6826 - accuracy: 0.7430 - val_loss: 0.4759 - val_accuracy: 0.8398\n",
      "Epoch 5/20\n",
      "49/49 [==============================] - 11s 216ms/step - loss: 0.5983 - accuracy: 0.7683 - val_loss: 0.4426 - val_accuracy: 0.8475\n",
      "Epoch 6/20\n",
      "49/49 [==============================] - 11s 216ms/step - loss: 0.5050 - accuracy: 0.8071 - val_loss: 0.3836 - val_accuracy: 0.8372\n",
      "Epoch 7/20\n",
      "49/49 [==============================] - 11s 218ms/step - loss: 0.4508 - accuracy: 0.8233 - val_loss: 0.3848 - val_accuracy: 0.8088\n",
      "Epoch 8/20\n",
      "49/49 [==============================] - 11s 222ms/step - loss: 0.3921 - accuracy: 0.8447 - val_loss: 0.3131 - val_accuracy: 0.8656\n",
      "Epoch 9/20\n",
      "49/49 [==============================] - 11s 224ms/step - loss: 0.3694 - accuracy: 0.8537 - val_loss: 0.2963 - val_accuracy: 0.8553\n",
      "Epoch 10/20\n",
      "49/49 [==============================] - 10s 211ms/step - loss: 0.3027 - accuracy: 0.8777 - val_loss: 0.2745 - val_accuracy: 0.8863\n",
      "Epoch 11/20\n",
      "49/49 [==============================] - 10s 203ms/step - loss: 0.3073 - accuracy: 0.8751 - val_loss: 0.2482 - val_accuracy: 0.9096\n",
      "Epoch 12/20\n",
      "49/49 [==============================] - 11s 218ms/step - loss: 0.3023 - accuracy: 0.8706 - val_loss: 0.2554 - val_accuracy: 0.8811\n",
      "Epoch 13/20\n",
      "49/49 [==============================] - 11s 216ms/step - loss: 0.2880 - accuracy: 0.8731 - val_loss: 0.2550 - val_accuracy: 0.8915\n",
      "Epoch 14/20\n",
      "49/49 [==============================] - 10s 213ms/step - loss: 0.2595 - accuracy: 0.8841 - val_loss: 0.2563 - val_accuracy: 0.9070\n",
      "Epoch 15/20\n",
      "49/49 [==============================] - 11s 215ms/step - loss: 0.2398 - accuracy: 0.9003 - val_loss: 0.2478 - val_accuracy: 0.8786\n",
      "Epoch 16/20\n",
      "49/49 [==============================] - 10s 209ms/step - loss: 0.2388 - accuracy: 0.8919 - val_loss: 0.2211 - val_accuracy: 0.9147\n",
      "Epoch 17/20\n",
      "49/49 [==============================] - 10s 212ms/step - loss: 0.2452 - accuracy: 0.9055 - val_loss: 0.2264 - val_accuracy: 0.8760\n",
      "Epoch 18/20\n",
      "49/49 [==============================] - 10s 213ms/step - loss: 0.2338 - accuracy: 0.9029 - val_loss: 0.2177 - val_accuracy: 0.9096\n",
      "Epoch 19/20\n",
      "49/49 [==============================] - 10s 209ms/step - loss: 0.2156 - accuracy: 0.8997 - val_loss: 0.2230 - val_accuracy: 0.9018\n",
      "Epoch 20/20\n",
      "49/49 [==============================] - 10s 210ms/step - loss: 0.2142 - accuracy: 0.9087 - val_loss: 0.1966 - val_accuracy: 0.9276\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 60, 60, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 30, 30, 64)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 30, 30, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 28, 28, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 14, 14, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               6422784   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 14)                3598      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6519630 (24.87 MB)\n",
      "Trainable params: 6519630 (24.87 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(64,64,3)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(14, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 29ms/step - loss: 0.1966 - accuracy: 0.9276\n",
      "Test loss: 0.1965695023536682\n",
      "Test accuracy: 0.9276486039161682\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Print test results\n",
    "print(f'Test loss: {test_loss}')\n",
    "print(f'Test accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_image(img_path, target_size=(64, 64)):\n",
    "    # Load the image\n",
    "    img = image.load_img(img_path, target_size=target_size)\n",
    "    # Convert the image to a numpy array\n",
    "    img_array = image.img_to_array(img)\n",
    "    # Normalize the image\n",
    "    img_array = img_array / 255.0\n",
    "    # Add batch dimension\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return img_array\n",
    "\n",
    "# Path to the image\n",
    "img_path = 'D:/Hackathon/Dell-AI-Hackathon-2024/Data/Tomato(1-5)/frame190.jpg'\n",
    "\n",
    "# Preprocess the image\n",
    "preprocessed_image = preprocess_image(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 103ms/step\n",
      "Predicted class index: 10\n",
      "{'Apple(1-5)': 0, 'Apple(10-14)': 1, 'Apple(5-10)': 2, 'Banana(1-5)': 3, 'Banana(10-15)': 4, 'Banana(15-20)': 5, 'Banana(5-10)': 6, 'Carrot(1-2)': 7, 'Carrot(3-4)': 8, 'Expired': 9, 'Tomato(1-5)': 10, 'Tomato(10-15)': 11, 'Tomato(5-10)': 12, 'carrot(5-6)': 13}\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(preprocessed_image)\n",
    "\n",
    "# Get the class index with the highest probability\n",
    "predicted_class_index = np.argmax(predictions[0])\n",
    "\n",
    "# Output the prediction\n",
    "print(f'Predicted class index: {predicted_class_index}')\n",
    "print(label_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model, _ = tf2onnx.convert.from_keras(model, opset=13)\n",
    "onnx.save(onnx_model,  \"Shelf_life.onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
